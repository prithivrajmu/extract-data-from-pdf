# Chandra OCR Model Loading Issues - Investigation Results

## üîç Findings

### 1. **Model Still Downloading** ‚¨áÔ∏è
- **Status**: One model shard (4.58 GB) is still being downloaded
- **Location**: `~/.cache/huggingface/hub/models--datalab-to--chandra/blobs/`
- **Issue**: Model cannot load until all shards are downloaded

### 2. **Multiple Processes Running** ‚ö†Ô∏è
- **Found**: 4 chandra processes running simultaneously
- **Impact**: 
  - Wastes system resources (CPU, memory, network)
  - Can slow down download speed
  - May cause conflicts
- **Action Taken**: Killed duplicate processes

### 3. **No GPU Available** üêå
- **Status**: Running on CPU only
- **Impact**: 
  - Model loading is **10-20x slower** on CPU
  - A 9B parameter model is very slow on CPU
  - Requires ~18GB RAM for CPU inference
- **Recommendation**: Use GPU if available for much faster processing

### 4. **Model Size**
- **Total size**: ~18GB (4 shards of ~4.5GB each)
- **Download progress**: 3 of 4 shards complete, 1 still downloading

## üõ†Ô∏è Solutions

### Immediate Actions:

1. **Wait for Download to Complete**
   ```bash
   # Monitor download progress
   python monitor_download.py
   ```
   
2. **Check Model Status**
   ```bash
   python diagnose_chandra.py
   ```

3. **Avoid Multiple Processes**
   - Don't run multiple extraction scripts simultaneously
   - Wait for current download/processing to finish

### Long-term Optimizations:

1. **Use GPU (Recommended)**
   - Install NVIDIA drivers
   - Install CUDA
   - GPU will speed up model loading by 10-20x
   - Reduces RAM requirement to ~10GB VRAM

2. **Monitor Progress**
   - Use `monitor_download.py` to watch download progress
   - Use `diagnose_chandra.py` to check model status

3. **Optimize First Run**
   - First run downloads model (one-time, ~18GB)
   - First inference is slower (JIT compilation)
   - Subsequent runs will be faster

## üìä Expected Timeline

- **Download time**: 10-20 minutes (depending on internet speed)
- **Model loading (CPU)**: 5-10 minutes
- **Model loading (GPU)**: 30 seconds - 2 minutes
- **Per page processing (CPU)**: 1-2 minutes per page
- **Per page processing (GPU)**: 5-10 seconds per page

## üéØ Current Status

‚úÖ Duplicate processes killed
‚è≥ Model download in progress (4.58 GB downloaded)
‚ö†Ô∏è Using CPU (much slower than GPU)
üì¶ Model cache: 17GB

## üí° Recommendations

1. **Wait for download to complete** - This is the main bottleneck
2. **Use GPU if available** - Will dramatically speed up processing
3. **Monitor progress** - Use the provided scripts to track status
4. **Be patient** - First run is always slowest

## üìù Files Created

- `diagnose_chandra.py` - Check model status and system configuration
- `monitor_download.py` - Real-time download progress monitoring
- `MODEL_LOADING_ISSUES.md` - This document



